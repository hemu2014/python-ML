{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hemu2014/python-ML/blob/main/test/Natural_Language_Processing_with_RNNs_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5cjtsHP8t5Y"
      },
      "source": [
        "#Natural Language Processing\n",
        "Natural Language Processing (or NLP for short) is a discipline in computing that deals with the communication between natural (human) languages and computer languages. A common example of NLP is something like spellcheck or autocomplete. Essentially NLP is the field that focuses on how computers can understand and/or process natural/human languages.\n",
        "\n",
        "###Recurrent Neural Networks\n",
        "\n",
        "In this tutorial we will introduce a new kind of neural network that is much more capable of processing sequential data such as text or characters called a **recurrent neural network** (RNN for short).\n",
        "\n",
        "We will learn how to use a reccurent neural network to do the following:\n",
        "- Sentiment Analysis\n",
        "- Character Generation\n",
        "\n",
        "RNN's are complex and come in many different forms so in this tutorial we wil focus on how they work and the kind of problems they are best suited for.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ur_FQq-Q-fxC"
      },
      "source": [
        "## Sequence Data\n",
        "In the previous tutorials we focused on data that we could represent as one static data point where the notion of time or step was irrelevant. Take for example our image data, it was simply a tensor of shape (width, height, channels). That data doesn't change or care about the notion of time.\n",
        "\n",
        "In this tutorial we will look at sequences of text and learn how we can encode them in a meaningful way. Unlike images, sequence data such as long chains of text, weather patterns, videos and really anything where the notion of a step or time is relevant needs to be processed and handled in a special way.\n",
        "\n",
        "But what do I mean by sequences and why is text data a sequence? Well that's a good question. Since textual data contains many words that follow in a very specific and meaningful order, we need to be able to keep track of each word and when it occurs in the data. Simply encoding say an entire paragraph of text into one data point wouldn't give us a very meaningful picture of the data and would be very difficult to do anything with. This is why we treat text as a sequence and process one word at a time. We will keep track of where each of these words appear and use that information to try to understand the meaning of peices of text.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gQHK4V4e2wl"
      },
      "source": [
        "##Encoding Text\n",
        "As we know machine learning models and neural networks don't take raw text data as an input. This means we must somehow encode our textual data to numeric values that our models can understand. There are many different ways of doing this and we will look at a few examples below.\n",
        "\n",
        "Before we get into the different encoding/preprocessing methods let's understand the information we can get from textual data by looking at the following two movie reviews.\n",
        "\n",
        "```I thought the movie was going to be bad, but it was actually amazing!```\n",
        "\n",
        "```I thought the movie was going to be amazing, but it was actually bad!```\n",
        "\n",
        "Although these two setences are very similar we know that they have very different meanings. This is because of the **ordering** of words, a very important property of textual data.\n",
        "\n",
        "Now keep that in mind while we consider some different ways of encoding our textual data.\n",
        "\n",
        "###Bag of Words\n",
        "The first and simplest way to encode our data is to use something called **bag of words**. This is a pretty easy technique where each word in a sentence is encoded with an integer and thrown into a collection that does not maintain the order of the words but does keep track of the frequency. Have a look at the python function below that encodes a string of text into bag of words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KiCCBsIkMHi"
      },
      "source": [
        "vocab = {}  # maps word to integer representing it\n",
        "word_encoding = 1\n",
        "def bag_of_words(text):\n",
        "  global word_encoding\n",
        "\n",
        "  words = text.lower().split(\" \")  # create a list of all of the words in the text, well assume there is no grammar in our text for this example\n",
        "  bag = {}  # stores all of the encodings and their frequency\n",
        "\n",
        "  for word in words:\n",
        "    if word in vocab:\n",
        "      encoding = vocab[word]  # get encoding from vocab\n",
        "    else:\n",
        "      vocab[word] = word_encoding\n",
        "      encoding = word_encoding\n",
        "      word_encoding += 1\n",
        "\n",
        "    if encoding in bag:\n",
        "      bag[encoding] += 1\n",
        "    else:\n",
        "      bag[encoding] = 1\n",
        "\n",
        "  return bag\n",
        "\n",
        "text = \"this is a test to see if this test will work is is test a a\"\n",
        "bag = bag_of_words(text)\n",
        "print(bag)\n",
        "print(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hEvstSBl1gy"
      },
      "source": [
        "This isn't really the way we would do this in practice, but I hope it gives you an idea of how bag of words works. Notice that we've lost the order in which words appear. In fact, let's look at how this encoding works for the two sentences we showed above.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miYshfvzmJ0H"
      },
      "source": [
        "positive_review = \"I thought the movie was going to be bad but it was actually amazing\"\n",
        "negative_review = \"I thought the movie was going to be amazing but it was actually bad\"\n",
        "\n",
        "pos_bag = bag_of_words(positive_review)\n",
        "neg_bag = bag_of_words(negative_review)\n",
        "\n",
        "print(\"Positive:\", pos_bag)\n",
        "print(\"Negative:\", neg_bag)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl7Fw9s3mkfK"
      },
      "source": [
        "We can see that even though these sentences have a very different meaning they are encoded exaclty the same way. Obviously, this isn't going to fly. Let's look at some other methods.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUKTycffmu1k"
      },
      "source": [
        "###Integer Encoding\n",
        "The next technique we will look at is called **integer encoding**. This involves representing each word or character in a sentence as a unique integer and maintaining the order of these words. This should hopefully fix the problem we saw before were we lost the order of words.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKY4y_tjnUEW"
      },
      "source": [
        "vocab = {}\n",
        "word_encoding = 1\n",
        "def one_hot_encoding(text):\n",
        "  global word_encoding\n",
        "\n",
        "  words = text.lower().split(\" \")\n",
        "  encoding = []\n",
        "\n",
        "  for word in words:\n",
        "    if word in vocab:\n",
        "      code = vocab[word]\n",
        "      encoding.append(code)\n",
        "    else:\n",
        "      vocab[word] = word_encoding\n",
        "      encoding.append(word_encoding)\n",
        "      word_encoding += 1\n",
        "\n",
        "  return encoding\n",
        "\n",
        "text = \"this is a test to see if this test will work is is test a a\"\n",
        "encoding = one_hot_encoding(text)\n",
        "print(encoding)\n",
        "print(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOrLG9Bin0Zv"
      },
      "source": [
        "And now let's have a look at one hot encoding on our movie reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S-GNjotn-Br"
      },
      "source": [
        "positive_review = \"I thought the movie was going to be bad but it was actually amazing\"\n",
        "negative_review = \"I thought the movie was going to be amazing but it was actually bad\"\n",
        "\n",
        "pos_encode = one_hot_encoding(positive_review)\n",
        "neg_encode = one_hot_encoding(negative_review)\n",
        "\n",
        "print(\"Positive:\", pos_encode)\n",
        "print(\"Negative:\", neg_encode)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jC9UYV4vpq6Y"
      },
      "source": [
        "Much better, now we are keeping track of the order of words and we can tell where each occurs. But this still has a few issues with it. Ideally when we encode words, we would like similar words to have similar labels and different words to have very different labels. For example, the words happy and joyful should probably have very similar labels so we can determine that they are similar. While words like horrible and amazing should probably have very different labels. The method we looked at above won't be able to do something like this for us. This could mean that the model will have a very difficult time determing if two words are similar or not which could result in some pretty drastic performace impacts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRZ73YCqqiw9"
      },
      "source": [
        "###Word Embeddings\n",
        "Luckily there is a third method that is far superior, **word embeddings**. This method keeps the order of words intact as well as encodes similar words with very similar labels. It attempts to not only encode the frequency and order of words but the meaning of those words in the sentence. It encodes each word as a dense vector that represents its context in the sentence.\n",
        "\n",
        "Unlike the previous techniques word embeddings are learned by looking at many different training examples. You can add what's called an *embedding layer* to the beggining of your model and while your model trains your embedding layer will learn the correct embeddings for words. You can also use pretrained embedding layers.\n",
        "\n",
        "This is the technique we will use for our examples and its implementation will be showed later on.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehig3qliuUzk"
      },
      "source": [
        "##Recurrent Neural Networks (RNN's)\n",
        "Now that we've learned a little bit about how we can encode text it's time to dive into recurrent neural networks. Up until this point we have been using something called **feed-forward** neural networks. This simply means that all our data is fed forwards (all at once) from left to right through the network. This was fine for the problems we considered before but won't work very well for processing text. After all, even we (humans) don't process text all at once. We read word by word from left to right and keep track of the current meaning of the sentence so we can understand the meaning of the next word. Well this is exaclty what a recurrent neural network is designed to do. When we say recurrent neural network all we really mean is a network that contains a loop. A RNN will process one word at a time while maintaining an internal memory of what it's already seen. This will allow it to treat words differently based on their order in a sentence and to slowly build an understanding of the entire input, one word at a time.\n",
        "\n",
        "This is why we are treating our text data as a sequence! So that we can pass one word at a time to the RNN.\n",
        "\n",
        "Let's have a look at what a recurrent layer might look like.\n",
        "\n",
        "![alt text](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png)\n",
        "*Source: https://colah.github.io/posts/2015-08-Understanding-LSTMs/*\n",
        "\n",
        "Let's define what all these variables stand for before we get into the explination.\n",
        "\n",
        "**h<sub>t</sub>** output at time t\n",
        "\n",
        "**x<sub>t</sub>** input at time t\n",
        "\n",
        "**A** Recurrent Layer (loop)\n",
        "\n",
        "What this diagram is trying to illustrate is that a recurrent layer processes words or input one at a time in a combination with the output from the previous iteration. So, as we progress further in the input sequence, we build a more complex understanding of the text as a whole.\n",
        "\n",
        "What we've just looked at is called a **simple RNN layer**. It can be effective at processing shorter sequences of text for simple problems but has many downfalls associated with it. One of them being the fact that as text sequences get longer it gets increasingly difficult for the network to understand the text properly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo3WY-e86zX2"
      },
      "source": [
        "##LSTM\n",
        "The layer we dicussed in depth above was called a *simpleRNN*. However, there does exist some other recurrent layers (layers that contain a loop) that work much better than a simple RNN layer. The one we will talk about here is called LSTM (Long Short-Term Memory). This layer works very similarily to the simpleRNN layer but adds a way to access inputs from any timestep in the past. Whereas in our simple RNN layer input from previous timestamps gradually disappeared as we got further through the input. With a LSTM we have a long-term memory data structure storing all the previously seen inputs as well as when we saw them. This allows for us to access any previous value we want at any point in time. This adds to the complexity of our network and allows it to discover more useful relationships between inputs and when they appear.\n",
        "\n",
        "For the purpose of this course we will refrain from going any further into the math or details behind how these layers work.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRGOx6_v4eZ_"
      },
      "source": [
        "##Sentiment Analysis\n",
        "And now time to see a recurrent neural network in action. For this example, we are going to do something called sentiment analysis.\n",
        "\n",
        "The formal definition of this term from Wikipedia is as follows:\n",
        "\n",
        "*the process of computationally identifying and categorizing opinions expressed in a piece of text, especially in order to determine whether the writer's attitude towards a particular topic, product, etc. is positive, negative, or neutral.*\n",
        "\n",
        "The example we’ll use here is classifying movie reviews as either postive, negative or neutral.\n",
        "\n",
        "*This guide is based on the following tensorflow tutorial: https://www.tensorflow.org/tutorials/text/text_classification_rnn*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RACGE5Ypt5u9"
      },
      "source": [
        "###Movie Review Dataset\n",
        "Well start by loading in the IMDB movie review dataset from keras. This dataset contains 25,000 reviews from IMDB where each one is already preprocessed and has a label as either positive or negative. Each review is encoded by integers that represents how common a word is in the entire dataset. For example, a word encoded by the integer 3 means that it is the 3rd most common word in the dataset.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdsus1kyXWC8"
      },
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "VOCAB_SIZE = 88584\n",
        "\n",
        "MAXLEN = 250\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh6lOpcQ9sIZ"
      },
      "source": [
        "# Lets look at one review\n",
        "train_data[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAtZHE9-eQ07"
      },
      "source": [
        "###More Preprocessing\n",
        "If we have a look at some of our loaded in reviews, we'll notice that they are different lengths. This is an issue. We cannot pass different length data into our neural network. Therefore, we must make each review the same length. To do this we will follow the procedure below:\n",
        "- if the review is greater than 250 words then trim off the extra words\n",
        "- if the review is less than 250 words add the necessary amount of 0's to make it equal to 250.\n",
        "\n",
        "Luckily for us keras has a function that can do this for us:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3qQ83sNeog6"
      },
      "source": [
        "train_data = sequence.pad_sequences(train_data, MAXLEN)\n",
        "test_data = sequence.pad_sequences(test_data, MAXLEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDm_0RTVir7I"
      },
      "source": [
        "###Creating the Model\n",
        "Now it's time to create the model. We'll use a word embedding layer as the first layer in our model and add a LSTM layer afterwards that feeds into a dense node to get our predicted sentiment.\n",
        "\n",
        "32 stands for the output dimension of the vectors generated by the embedding layer. We can change this value if we'd like!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWGGcBIpjrMu"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(VOCAB_SIZE, 32),\n",
        "    tf.keras.layers.LSTM(32),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8_jPL_Kkr-a"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyeQCk3LlK6V"
      },
      "source": [
        "###Training\n",
        "Now it's time to compile and train the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKEMjaIulPBe"
      },
      "source": [
        "model.compile(loss=\"binary_crossentropy\",optimizer=\"rmsprop\",metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_data, train_labels, epochs=10, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3buYlkkhoK93"
      },
      "source": [
        "And we'll evaluate the model on our training data to see how well it performs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KImNMWTDoJaQ"
      },
      "source": [
        "results = model.evaluate(test_data, test_labels)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1RRGcr9CFCW"
      },
      "source": [
        "So we're scoring somewhere in the mid-high 80's. Not bad for a simple recurrent network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGrBRC4YCObV"
      },
      "source": [
        "###Making Predictions\n",
        "Now let’s use our network to make predictions on our own reviews.\n",
        "\n",
        "Since our reviews are encoded well need to convert any review that we write into that form so the network can understand it. To do that well load the encodings from the dataset and use them to encode our own data.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Onu8leY4Cn9z"
      },
      "source": [
        "word_index = imdb.get_word_index()\n",
        "\n",
        "def encode_text(text):\n",
        "  tokens = keras.preprocessing.text.text_to_word_sequence(text)\n",
        "  tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
        "  return sequence.pad_sequences([tokens], MAXLEN)[0]\n",
        "\n",
        "text = \"that movie was just amazing, so amazing\"\n",
        "encoded = encode_text(text)\n",
        "print(encoded)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKna3vxmFwrB"
      },
      "source": [
        "# while were at it lets make a decode function\n",
        "\n",
        "reverse_word_index = {value: key for (key, value) in word_index.items()}\n",
        "\n",
        "def decode_integers(integers):\n",
        "    PAD = 0\n",
        "    text = \"\"\n",
        "    for num in integers:\n",
        "      if num != PAD:\n",
        "        text += reverse_word_index[num] + \" \"\n",
        "\n",
        "    return text[:-1]\n",
        "\n",
        "print(decode_integers(encoded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8nyrr00HPZF"
      },
      "source": [
        "# now time to make a prediction\n",
        "\n",
        "def predict(text):\n",
        "  encoded_text = encode_text(text)\n",
        "  pred = np.zeros((1,250))\n",
        "  pred[0] = encoded_text\n",
        "  result = model.predict(pred)\n",
        "  print(result[0])\n",
        "\n",
        "positive_review = \"That movie was! really loved it and would great watch it again because it was amazingly great\"\n",
        "predict(positive_review)\n",
        "\n",
        "negative_review = \"that movie really sucked. I hated it and wouldn't watch it again. Was one of the worst things I've ever watched\"\n",
        "predict(negative_review)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01BJLcGb4ZqK"
      },
      "source": [
        "##RNN Play Generator\n",
        "\n",
        "Now time for one of the coolest examples we've seen so far. We are going to use a RNN to generate a play. We will simply show the RNN an example of something we want it to recreate and it will learn how to write a version of it on its own. We'll do this using a character predictive model that will take as input a variable length sequence and predict the next character. We can use the model many times in a row with the output from the last predicition as the input for the next call to generate a sequence.\n",
        "\n",
        "\n",
        "*This guide is based on the following: https://www.tensorflow.org/tutorials/text/text_generation*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fju7i1FKrK_G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbca862f-73ac-4bd1-fc9c-6694a5d3980a"
      },
      "source": [
        "%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F48c-EctQ378"
      },
      "source": [
        "###Dataset\n",
        "For this example, we only need one peice of training data. In fact, we can write our own poem or play and pass that to the network for training if we'd like. However, to make things easy we'll use an extract from a shakesphere play.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdRcVIhtRGlF"
      },
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlSVGd5ACkZe"
      },
      "source": [
        "###Loading Your Own Data\n",
        "To load your own data, you'll need to upload a file from the dialog below. Then you'll need to follow the steps from above but load in this new file instead.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####这个模块是 Google Colab 提供的，用于在 Colab 环境中处理文件上传和下载。"
      ],
      "metadata": {
        "id": "Flz9ekr6ekuA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFYFwbJOC3bP"
      },
      "source": [
        "from google.colab import files\n",
        "path_to_file = list(files.upload().keys())[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtJMEqQyRhAk"
      },
      "source": [
        "###Read Contents of File\n",
        "Let's look at the contents of the file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-n4oovOMRnP7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "761fa91b-878d-4041-d639-6cf8d9957503"
      },
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print ('Length of text: {} characters'.format(len(text)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####查看前250的字符"
      ],
      "metadata": {
        "id": "Uk_4P4mheNSB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHUxQVl7Rt10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95733a9d-ea62-4e1a-d126-3d29f31b2e44"
      },
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vt8Vpe0RvaJ"
      },
      "source": [
        "###Encoding\n",
        "Since this text isn't encoded yet well need to do that ourselves. We are going to encode each unique character as a different integer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7AZNI7aRz6y"
      },
      "source": [
        "vocab = sorted(set(text))  # 使用集合将字符变位唯一的值，然后进行排序, 构建文本的词汇表（vocabulary），即所有可能出现的唯一字符的集合。\n",
        "# Creating a mapping from unique characters to indices\n",
        "#生成一个字典，将每个字符映射到对应的索引（整数）：\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}  # 将vocal中的字符以字典形式，如:{char: index}\n",
        "#用途：将字符转换为模型可处理的数字（如 'h' → 1）。\n",
        "#将vocab转换为NumPy数组，用于通过索引反向查找字符：,本身char2idx字典就是同过索引进行构建的\n",
        "idx2char = np.array(vocab)\n",
        "#用途：将模型输出的数字转换回字符（如 1 → 'h'）。\n",
        "def text_to_int(text):\n",
        "  return np.array([char2idx[c] for c in text])  #返回一个对应索引的数组\n",
        "\n",
        "text_as_int = text_to_int(text)  #将文本全部转为数字"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* A-Z： 13-38，\n",
        "* a-z: 39-64\n",
        "* 空格： 1， 不同的文本不一样，只针对当前文本"
      ],
      "metadata": {
        "id": "5K8Wfo--gTsw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i5kvmX_SLW4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a55e74f5-1885-4728-d150-97bc4fbca430"
      },
      "source": [
        "# lets look at how part of our text is encoded\n",
        "print(\"Text:\", text[:13])\n",
        "print(\"Encoded:\", text_to_int(text[:13]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: First Citizen\n",
            "Encoded: [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDvD5kqTWwOn"
      },
      "source": [
        "And here we will make a function that can convert our numeric values to text.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af52YChSW5hX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cdd99e8-05f3-4068-e902-801dea5285d3"
      },
      "source": [
        "def int_to_text(ints):\n",
        "  try:\n",
        "    ints = ints.numpy()  # 将列表转为numpy数组-如果输入 ints 是 TensorFlow 张量（如模型输出），将其转换为 NumPy 数组。\n",
        "  except:\n",
        "    pass #如果已经是 NumPy 数组或列表，.numpy() 会抛出异常，此时直接跳过（pass）。\n",
        "  return ''.join(idx2char[ints]) # 将索引转为对应的字符，进行连接\n",
        "print(text_as_int[:13])  # 取前13个字符\n",
        "print(int_to_text(text_as_int[:13]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18 47 56 57 58  1 15 47 58 47 64 43 52]\n",
            "First Citizen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_49cl6uS0r-"
      },
      "source": [
        "###Creating Training Examples\n",
        "Remember our task is to feed the model a sequence and have it return to us the next character. This means we need to split our text data from above into many shorter sequences that we can pass to the model as training examples.\n",
        "\n",
        "The training examples we will prepapre will use a *seq_length* sequence as input and a *seq_length* sequence as the output where that sequence is the original sequence shifted one letter to the right. For example:\n",
        "\n",
        "```input: Hell | output: ello```\n",
        "\n",
        "Our first step will be to create a stream of characters from our text data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBkXz9fjUQHW"
      },
      "source": [
        "seq_length = 100  # length of sequence for a training example\n",
        "examples_per_epoch = len(text)//(seq_length+1)\n",
        "\n",
        "# Create training examples / targets\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqmxfT7gVGlr"
      },
      "source": [
        "Next we can use the batch method to turn this stream of characters into batches of desired length."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####drop_remainder=True 会丢弃不足 seq_length+1 的剩余字符。\n",
        "将长序列分割成多个 seq_length+1 的块"
      ],
      "metadata": {
        "id": "n6DE5hVOkR3X"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi0xaPB_VOJl"
      },
      "source": [
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxo1Dig_VvV1"
      },
      "source": [
        "Now we need to use these sequences of length 101 and split them into input and output."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* map 操作：\n",
        "对 sequences 中的每个块应用 split_input_target 函数，生成最终的训练数据集 dataset。\n",
        "\n",
        "* 数据集结构：\n",
        "每个样本是 (input_text, target_text) 的元组，其中：\n",
        "\n",
        " input_text 和 target_text 的长度均为 seq_length。\n",
        "\n",
        "* 示例：\n",
        "* 若分块为 [1, 2, 3] 和 [4, 5, 6]，则转换后：\n",
        "\n",
        "* input_text=[1, 2], target_text=[2, 3]\n",
        "\n",
        "* input_text=[4, 5], target_text=[5, 6]"
      ],
      "metadata": {
        "id": "TRvWOEm0nWdl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03zKVHTvV0Km"
      },
      "source": [
        "def split_input_target(chunk):  # for the example: hello\n",
        "    input_text = chunk[:-1]  # hell， 输入\n",
        "    target_text = chunk[1:]  # ello， 输出\n",
        "    return input_text, target_text  # hell, ello\n",
        "\n",
        "#每个样本的前 seq_length 个字符是输入，最后一个字符是目标：\n",
        "dataset = sequences.map(split_input_target)  # we use map to apply the above function to every entry\n",
        "#或者直接使用lambda函数\n",
        "#dataset = sequences.map(lambda chunk: (chunk[:-1], chunk[1:]))\n",
        "# 每个样本是 (input_text, target_text) 的元组"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "RSh4Yk0vn1tl"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p_y2YmgWbnc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed6e1c24-8053-4d18-ddb8-567e8cbfc012"
      },
      "source": [
        "for x, y in dataset.take(2):\n",
        "  print(x)\n",
        "  print(y)\n",
        "  print(\"\\n\\nEXAMPLE\\n\")\n",
        "  print(\"INPUT\")\n",
        "  print(int_to_text(x))\n",
        "  print(\"\\nOUTPUT\")\n",
        "  print(int_to_text(y))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
            "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
            " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
            "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
            "  0 37 53 59], shape=(100,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43  1\n",
            " 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43 39\n",
            " 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49  6\n",
            "  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0\n",
            " 37 53 59  1], shape=(100,), dtype=int64)\n",
            "\n",
            "\n",
            "EXAMPLE\n",
            "\n",
            "INPUT\n",
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You\n",
            "\n",
            "OUTPUT\n",
            "irst Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You \n",
            "tf.Tensor(\n",
            "[39 56 43  1 39 50 50  1 56 43 57 53 50 60 43 42  1 56 39 58 46 43 56  1\n",
            " 58 53  1 42 47 43  1 58 46 39 52  1 58 53  1 44 39 51 47 57 46 12  0  0\n",
            " 13 50 50 10  0 30 43 57 53 50 60 43 42  8  1 56 43 57 53 50 60 43 42  8\n",
            "  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 18 47 56 57 58  6  1\n",
            " 63 53 59  1], shape=(100,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[56 43  1 39 50 50  1 56 43 57 53 50 60 43 42  1 56 39 58 46 43 56  1 58\n",
            " 53  1 42 47 43  1 58 46 39 52  1 58 53  1 44 39 51 47 57 46 12  0  0 13\n",
            " 50 50 10  0 30 43 57 53 50 60 43 42  8  1 56 43 57 53 50 60 43 42  8  0\n",
            "  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 18 47 56 57 58  6  1 63\n",
            " 53 59  1 49], shape=(100,), dtype=int64)\n",
            "\n",
            "\n",
            "EXAMPLE\n",
            "\n",
            "INPUT\n",
            "are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you \n",
            "\n",
            "OUTPUT\n",
            "re all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6OxuFKVXpwK"
      },
      "source": [
        "Finally we need to make training batches."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 目的：将已经**分好的子序列块组合成训练批次**，每批次包含** BATCH_SIZE 个样本。**\n",
        "\n",
        "* 输入：经过 split_input_target 处理后的 (input_text, target_text) 对（每个长度=100）。\n",
        "\n",
        "* 输出：**形状为 (BATCH_SIZE, seq_length) 的张量**。（64，100）\n",
        "\n",
        "* 为什么需要这个操作？\n",
        "GPU/TPU 需要并行处理多个样本（即一个批次）以提高效率，而不是逐个处理。"
      ],
      "metadata": {
        "id": "wM-Ka0kYq7rE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRsKcjhXXuoD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "479da113-d318-43fe-8b8a-c4f391a9c27a"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "VOCAB_SIZE = len(vocab)  # vocab is number of unique characters\n",
        "EMBEDDING_DIM = 256\n",
        "RNN_UNITS = 1024\n",
        "print(type(vocab))\n",
        "print(vocab)\n",
        "print(VOCAB_SIZE)\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "# 将前面分成的101序列块，每BATCH_SIZE的大小作为一个批次\n",
        "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6YRmZLtX0d0"
      },
      "source": [
        "###Building the Model\n",
        "Now it is time to build the model. We will use an embedding layer a LSTM and one dense layer that contains a node for each unique character in our training data. The dense layer will give us a probability distribution over all nodes."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "# 这段代码之所以会提示 ValueError: Unrecognized keyword arguments passed to\n",
        "Embedding: {'batch_input_shape': [64, None]}，是因为\n",
        "tf.keras.layers.Embedding 层没有名为 batch_input_shape 的参数。\n",
        "\n",
        "```\n",
        "* batch_input_shape 是用于指定模型输入的形状，包括批次大小（当批次大小固定时，特别是对于有状态的 RNN）。在 Keras 的 Sequential 模型中，通常有几种方式来指定输入形状：\n",
        "\n",
        "* 在第一层使用 input_shape： 这会为模型自动创建一个 InputLayer，但不包含批次大小**（批次大小默认为 None，即不固定）。**\n",
        "* 在第一层使用 batch_input_shape： 这会为模型自动创建一个 InputLayer，并**指定包含批次大小在内的完整输入形状。这对于需要固定批次大小的情况（例如有状态的 RNN）是必需的。**\n",
        "* 显式添加 tf.keras.Input 层作为 Sequential 模型的第一项： 这是最灵活的方式，可以精确控制输入的名称、形状、dtype 等。\n",
        "* 对于你代码中的情况，你在 Embedding 层中使用了 batch_input_shape。然而，Embedding 层本身并不直接接受 batch_input_shape 参数。Embedding 层主要关注词汇表大小 (input_dim) 和嵌入维度 (output_dim)，以及可选的输入序列长度 (input_length)。输入数据的批次形状通常由模型整体或前一个层（如果存在的话）确定。\n",
        "\n",
        "* 考虑到你的** LSTM 层设置了 stateful=True，这意味着你需要一个固定批次大小的输入。在 Keras 的 Sequential 模型中，**当使用**有状态层时，你应该在第一个有状态层中指定 batch_input_shape**。在你的代码中，第一个有状态层是 tf.keras.layers.LSTM。\n",
        "\n"
      ],
      "metadata": {
        "id": "zh02OxxDz1Gw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v_P2dEic4qt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "f7e57607-d5af-41c2-afe2-a420815b8210"
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "  model = tf.keras.Sequential([\n",
        "      # 使用 Input 层明确指定输入形状\n",
        "      #tf.keras.layers.Input(shape=(None,), batch_size=batch_size),  # 明确批次和序列长度\n",
        "    tf.keras.layers.Embedding(vocab_size,\n",
        "                embedding_dim,\n",
        "                #batch_input_shape=[batch_size, None]\n",
        "                              ),\n",
        "    tf.keras.layers.LSTM(rnn_units,\n",
        "              return_sequences=True,\n",
        "              stateful=True,\n",
        "              recurrent_initializer='glorot_uniform'),\n",
        "    tf.keras.layers.Dense(vocab_size)\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "model = build_model(VOCAB_SIZE,EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
        "model.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.build(input_shape=(BATCH_SIZE, None))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "zM-CrVrTu_NL",
        "outputId": "be69a7b0-511d-4da0-bf46-d793613716fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m16,640\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)       │     \u001b[38;5;34m5,246,976\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)         │        \u001b[38;5;34m66,625\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,640</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,246,976</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,625</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,330,241\u001b[0m (20.33 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,330,241</span> (20.33 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,330,241\u001b[0m (20.33 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,330,241</span> (20.33 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gfnHBUOvPqE"
      },
      "source": [
        "###Creating a Loss Function\n",
        "Now we are going to create our own loss function for this problem. This is because our model will output a (64, sequence_length, 65) shaped tensor that represents the probability distribution of each character at each timestep for every sequence in the batch.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_ERM4F15v_S"
      },
      "source": [
        "However, before we do that let's have a look at a sample input and the output from our untrained model. This is so we can understand what the model is giving us.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###(64, 100, 65) 表示**64个样本**，每个样本**100个时间步**，每个时间**步65维特征**。"
      ],
      "metadata": {
        "id": "o6j5eWG-4l-e"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdvEqlwc6_q0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9416333-6d5a-408a-c8f4-13fa18a4ed44"
      },
      "source": [
        "for input_example_batch, target_example_batch in data.take(1):\n",
        "  # 输入数据形状\n",
        "  print(input_example_batch.shape)\n",
        "\n",
        "  #请求我们的模型对我们第一批训练数据（64 个条目）进行预测\n",
        "  example_batch_predictions = model(input_example_batch)  # ask our model for a prediction on our first batch of training data (64 entries)\n",
        "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")  # print out the output shape\n",
        "  print(example_batch_predictions[0][0])\n",
        "  print(example_batch_predictions[0][1])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100)\n",
            "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n",
            "tf.Tensor(\n",
            "[-3.2696445e-03 -1.2376723e-02  3.8370239e-03  5.9226742e-03\n",
            "  8.4966398e-04  6.3707819e-04 -3.2248683e-03  4.6792319e-03\n",
            "  8.4826723e-03 -1.0885636e-02 -5.6860242e-03 -5.8723614e-03\n",
            "  6.5149250e-03  5.1831297e-04 -2.4613808e-04 -1.8955334e-03\n",
            "  1.0494817e-03  3.7045146e-03  1.6457622e-03 -5.6579709e-03\n",
            "  7.6488657e-03 -1.1541422e-03  3.3561406e-03  2.5350940e-03\n",
            "  2.5231296e-03 -1.7193683e-03 -7.8233397e-03 -3.7670000e-03\n",
            " -2.3238631e-03  4.9749459e-03 -1.0043662e-03 -1.3106775e-02\n",
            " -1.1717054e-02 -1.3429457e-03  8.0738002e-03  4.0285839e-03\n",
            "  4.0602903e-03 -4.1072333e-04  4.2157806e-03 -3.8029253e-03\n",
            " -6.7795520e-03  1.4221622e-03  7.3611336e-03  5.5985488e-03\n",
            " -3.6038601e-04  9.3762123e-05 -9.9102221e-03 -7.4549182e-04\n",
            " -8.5672643e-03  2.6739445e-03  4.3251431e-03 -3.5098370e-03\n",
            "  5.6596408e-03  4.0573082e-03 -9.2081977e-03  1.2552817e-03\n",
            "  2.3982709e-03  1.2699397e-02 -2.4637638e-04  1.3244777e-02\n",
            " -3.3090811e-03  1.1414931e-02  5.6107761e-03 -4.3406999e-03\n",
            "  5.4493346e-03], shape=(65,), dtype=float32)\n",
            "tf.Tensor(\n",
            "[-0.00074242 -0.01344217  0.00054824  0.00835554  0.00266728 -0.00198484\n",
            " -0.00108205  0.00440369  0.00624036 -0.01581885 -0.01062866 -0.00100838\n",
            "  0.00715656 -0.00201932 -0.00344668 -0.00192014 -0.00404424  0.00105392\n",
            "  0.00241085 -0.00588634  0.00672878  0.00178901  0.00241915  0.00175638\n",
            " -0.00686568 -0.00052046 -0.00795599 -0.00398795  0.00115777  0.00308077\n",
            "  0.00114725 -0.00637099 -0.01361915 -0.00313855  0.00903547  0.00830856\n",
            "  0.00649358  0.00185805  0.01053618 -0.00606855 -0.00439153  0.0016508\n",
            "  0.0075117   0.00855727 -0.00691236  0.00518948 -0.00215424 -0.00120592\n",
            " -0.00529864 -0.0001087   0.00232074 -0.00368397  0.00428614  0.00767302\n",
            " -0.00648531 -0.0041152   0.00912086  0.00965693 -0.00281522  0.01123702\n",
            " -0.00437003  0.01018987  0.0064918  -0.00775122  0.00598779], shape=(65,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQS5KXwi7_NX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9222daec-e541-478f-e8ca-abdd87f865af"
      },
      "source": [
        "# we can see that the predicition is an array of 64 arrays, one for each entry in the batch\n",
        "print(len(example_batch_predictions)) #获取的是第一个维度64， （64,100,65）\n",
        "print(example_batch_predictions[0][2])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64\n",
            "tf.Tensor(\n",
            "[ 0.00470225 -0.01413222  0.00238819  0.01187135 -0.00033031  0.00175647\n",
            " -0.00398558  0.0039864   0.0055445  -0.01421509 -0.00833448 -0.00921352\n",
            "  0.00957203 -0.00058308 -0.00148188 -0.00406361 -0.00180265  0.00356982\n",
            "  0.00604601 -0.00125827  0.00782033  0.00221363  0.00230867  0.00561536\n",
            " -0.00480284 -0.00416142 -0.01409853 -0.00654454 -0.00550266  0.00695849\n",
            "  0.00106328 -0.00676918 -0.01267423 -0.00051168  0.01040247  0.00199739\n",
            "  0.00106481  0.0029334   0.01510281 -0.00271383 -0.00238983 -0.00082306\n",
            "  0.00320973  0.00616054 -0.00546499  0.00557436 -0.00160319  0.00208347\n",
            " -0.00547659 -0.00548695 -0.00482577 -0.00320398  0.00113715  0.00410811\n",
            " -0.01190187  0.00212105  0.01309738  0.01198968 -0.00702292  0.01302649\n",
            " -0.00455395  0.00238113  0.00584009 -0.00748114  0.00374455], shape=(65,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sA1Zhop28V9n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31ffd481-a442-470a-bfdb-18e2e90588d8"
      },
      "source": [
        "# lets examine one prediction\n",
        "pred = example_batch_predictions[0]  # (100,65)\n",
        "print(len(pred)) # 获取第一个维度100\n",
        "print(pred)\n",
        "# notice this is a 2d array of length 100, where each interior array is the prediction for the next character at each time step"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "tf.Tensor(\n",
            "[[-3.2696445e-03 -1.2376723e-02  3.8370239e-03 ...  5.6107761e-03\n",
            "  -4.3406999e-03  5.4493346e-03]\n",
            " [-7.4241543e-04 -1.3442170e-02  5.4824067e-04 ...  6.4918017e-03\n",
            "  -7.7512152e-03  5.9877853e-03]\n",
            " [ 4.7022486e-03 -1.4132218e-02  2.3881912e-03 ...  5.8400920e-03\n",
            "  -7.4811368e-03  3.7445477e-03]\n",
            " ...\n",
            " [ 5.9592929e-03 -4.1347439e-03 -9.6491864e-04 ...  1.1159776e-02\n",
            "  -5.2324440e-03  4.7986093e-04]\n",
            " [ 7.3333024e-03 -5.9105516e-03  2.8921640e-05 ...  1.3939661e-02\n",
            "  -4.8860307e-03 -3.1912522e-03]\n",
            " [ 1.1219820e-02 -9.7206086e-03  2.8178464e-03 ...  1.1770212e-02\n",
            "  -3.5969992e-03 -4.5317477e-03]], shape=(100, 65), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbIoe7Ei8q3q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4608354-eef2-4685-e3b0-9bbb8609ec4d"
      },
      "source": [
        "# and finally well look at a prediction at the first timestep\n",
        "time_pred = pred[0]  #（65，）\n",
        "print(len(time_pred))\n",
        "print(time_pred)\n",
        "# and of course its 65 values representing the probabillity of each character occuring next"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n",
            "tf.Tensor(\n",
            "[-3.2696445e-03 -1.2376723e-02  3.8370239e-03  5.9226742e-03\n",
            "  8.4966398e-04  6.3707819e-04 -3.2248683e-03  4.6792319e-03\n",
            "  8.4826723e-03 -1.0885636e-02 -5.6860242e-03 -5.8723614e-03\n",
            "  6.5149250e-03  5.1831297e-04 -2.4613808e-04 -1.8955334e-03\n",
            "  1.0494817e-03  3.7045146e-03  1.6457622e-03 -5.6579709e-03\n",
            "  7.6488657e-03 -1.1541422e-03  3.3561406e-03  2.5350940e-03\n",
            "  2.5231296e-03 -1.7193683e-03 -7.8233397e-03 -3.7670000e-03\n",
            " -2.3238631e-03  4.9749459e-03 -1.0043662e-03 -1.3106775e-02\n",
            " -1.1717054e-02 -1.3429457e-03  8.0738002e-03  4.0285839e-03\n",
            "  4.0602903e-03 -4.1072333e-04  4.2157806e-03 -3.8029253e-03\n",
            " -6.7795520e-03  1.4221622e-03  7.3611336e-03  5.5985488e-03\n",
            " -3.6038601e-04  9.3762123e-05 -9.9102221e-03 -7.4549182e-04\n",
            " -8.5672643e-03  2.6739445e-03  4.3251431e-03 -3.5098370e-03\n",
            "  5.6596408e-03  4.0573082e-03 -9.2081977e-03  1.2552817e-03\n",
            "  2.3982709e-03  1.2699397e-02 -2.4637638e-04  1.3244777e-02\n",
            " -3.3090811e-03  1.1414931e-02  5.6107761e-03 -4.3406999e-03\n",
            "  5.4493346e-03], shape=(65,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlEYM1H995gR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "23474741-5c3c-4dd9-bdc1-5e63aa800f8c"
      },
      "source": [
        "# If we want to determine the predicted character we need to sample the output distribution (pick a value based on probabillity)\n",
        "#我们需要确定预测字符，需要采样输出分布（根据概率选择一个值）\n",
        "#通过 tf.random.categorical 或 tf.argmax 转换为字符索引：\n",
        "sampled_indices = tf.random.categorical(pred, num_samples=1) # pred(100,65) num_samples=1：每个时间步采样1个字符。\n",
        "print(sampled_indices.shape)\n",
        "#现在我们可以重塑该数组并将所有整数转换为数字以查看实际字符\n",
        "# now we can reshape that array and convert all the integers to numbers to see the actual characters\n",
        "\n",
        "# 重塑的形状是将（100,1）==》（1,100），使用[0]取第一个数据也就是（100，）\n",
        "# 也是int_to_text函数需要的形状， 或者直接np.reshape(sampled_indices, (-1，))，直接改为（100，）\n",
        "sampled_indices = np.reshape(sampled_indices, (1,-1))[0]\n",
        "\n",
        "\n",
        "print(sampled_indices)\n",
        "print(sampled_indices.shape)\n",
        "predicted_chars = int_to_text(sampled_indices)\n",
        "## 并且这是模型对训练序列1的预测\n",
        "predicted_chars  # and this is what the model predicted for training sequence 1"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 1)\n",
            "[37 21 56 11 21 61  9 48 53 35  4 23 37 37 25  5 37 43 19 36 45 56 12 56\n",
            "  6 17 54 30 14 37 28 44 15 11  4 29 59 21 18 51 41 42 25  7 44 59  5 36\n",
            " 44 62 34  5 10 26 26  7 35 23 44 23 47 35 63 28 18 33 52 14 31 41 45 43\n",
            " 59 56 24 64 47 37 12  7 32 30 12 42 62 12 36 22  9 52 14  8 20  5  3 49\n",
            " 22 29  9 22]\n",
            "(100,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"YIr;Iw3joW&KYYM'YeGXgr?r,EpRBYPfC;&QuIFmcdM-fu'XfxV':NN-WKfKiWyPFUnBScgeurLziY?-TR?dx?XJ3nB.H'$kJQ3J\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcCBfPjN9Cnp"
      },
      "source": [
        "So now we need to create a loss function that can compare that output to the expected output and give us some numeric value representing how close the two were."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOw23fWq9D9O"
      },
      "source": [
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcg75GwXgW81"
      },
      "source": [
        "###Compiling the Model\n",
        "At this point we can think of our problem as a classification problem where the model predicts the probabillity of each unique letter coming next.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "metadata": {
        "id": "v-Skxor2Ahli",
        "outputId": "cda1e91c-f6c9-4a57-fd0f-8d2c80de96ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 65)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       4.174199\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "未经训练的模型输出的损失值应接近 -log(1/vocab_size)（随机猜测的理论值）。例如，若 vocab_size=65，初始损失应在 -log(1/65) ≈ 4.17 左右。"
      ],
      "metadata": {
        "id": "nt7chxZOEf2R"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g6o7zA_hAiS"
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgDKr4yvjLPI"
      },
      "source": [
        "###Creating Checkpoints\n",
        "Now we are going to setup and configure our model to save checkpoinst as it trains. This will allow us to load our model from a checkpoint and continue training it."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 通过将 checkpoint_prefix 修改为 os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")，您告诉 ModelCheckpoint 回调函数将模型的权重以 .weights.h5 格式保存到指定的文件路径中，文件名会包含当前的训练轮数。\n",
        "\n",
        "重要提示\n",
        "\n",
        "* 仅保存权重 (save_weights_only=True)： 这种方式只保存模型的可训练权重。\n",
        "* 如果您需要保存模型的完整结构（包括层配置、优化器状态等），则应该将 save_weights_only 设置为 False，并且 filepath 通常以 .h5 或 .keras 结尾。\n",
        "* 目录存在： 再次确认 ./training_checkpoints 目录是存在的并且可写的。"
      ],
      "metadata": {
        "id": "heiyKgIJBUta"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7aMushYjSpy"
      },
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p7acPvGja5c"
      },
      "source": [
        "###Training\n",
        "Finally, we will start training the model.\n",
        "\n",
        "**If this is taking a while go to Runtime > Change Runtime Type and choose \"GPU\" under hardware accelerator.**\n",
        "\n"
      ]
    },
    {
      "source": [
        "# Assuming 'data' is your _BatchDataset object, in this case dataset\n",
        "for element in dataset.take(1):  # Get the first element from the dataset\n",
        "    input_text, target_text = element # Unpack the tuple\n",
        "    print(input_text.shape, target_text.shape)     # Print the shapes of the elements"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "Ej8PgOu6FkfB",
        "outputId": "f4d5b289-bc91-4ba5-e7d4-a48e128ef8cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100,) (100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4PAgrwMjZ4_"
      },
      "source": [
        "history = model.fit(data, epochs=50, callbacks=[checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GhoHJVtmTsz"
      },
      "source": [
        "###Loading the Model\n",
        "We'll rebuild the model from a checkpoint using a batch_size of 1 so that we can feed one peice of text to the model and have it make a prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPSto3uimSKp"
      },
      "source": [
        "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boEJvy_vjLJQ"
      },
      "source": [
        "Once the model is finished training, we can find the **lastest checkpoint** that stores the models weights using the following line.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZIEZWE4mNKl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "0f96a4e6-97b1-4980-de0d-884029046bc0"
      },
      "source": [
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "File format not supported: filepath=None. Keras 3 only supports V3 `.keras` and `.weights.h5` files, or legacy V1/V2 `.h5` files.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-23e756025d16>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(model, filepath, skip_mismatch, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0mlegacy_h5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    276\u001b[0m             \u001b[0;34mf\"File format not supported: filepath={filepath}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0;34m\"Keras 3 only supports V3 `.keras` and `.weights.h5` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: File format not supported: filepath=None. Keras 3 only supports V3 `.keras` and `.weights.h5` files, or legacy V1/V2 `.h5` files."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmPPtbaTKF8d"
      },
      "source": [
        "We can load **any checkpoint** we want by specifying the exact file to load."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ_5p0ehKFDn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "269699bb-d936-4060-d22a-98fb5b07e5aa"
      },
      "source": [
        "checkpoint_num = 10\n",
        "model.load_weights(tf.train.load_checkpoint(\"./training_checkpoints/ckpt_\" + str(checkpoint_num)))\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./training_checkpoints/ckpt_10",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m     91\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m   \u001b[0;31m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./training_checkpoints/ckpt_10",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-97614ead033d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcheckpoint_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./training_checkpoints/ckpt_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/training/checkpoint_utils.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(ckpt_dir_or_file)\u001b[0m\n\u001b[1;32m     78\u001b[0m     raise ValueError(\"Couldn't find 'checkpoint' file or checkpoints in \"\n\u001b[1;32m     79\u001b[0m                      \"given directory %s\" % ckpt_dir_or_file)\n\u001b[0;32m---> 80\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mpy_checkpoint_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m     94\u001b[0m   \u001b[0;31m# issue with throwing python exceptions from C++.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0merror_translator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/training/py_checkpoint_reader.py\u001b[0m in \u001b[0;36merror_translator\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0;34m'Failed to find any '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       'matching files for') in error_message:\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m   elif 'Sliced checkpoints are not supported' in error_message or (\n\u001b[1;32m     33\u001b[0m       \u001b[0;34m'Data type '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ./training_checkpoints/ckpt_10"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaZWalEeAxQN"
      },
      "source": [
        "###Generating Text\n",
        "Now we can use the lovely function provided by tensorflow to generate some text using any starting string we'd like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPSALdQXA3l3"
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "  # Evaluation step (generating text using the learned model)\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = 800\n",
        "\n",
        "  # Converting our start string to numbers (vectorizing)\n",
        "  input_eval = [char2idx[s] for s in start_string]\n",
        "'''\n",
        " 使用 tf.expand_dims 函数在 input_eval 的最前面添加一个维度。这会将input_eval从一个形状为(length_of_start_string,)\n",
        " 的列表或一维数组转换为一个形状为(1,length_of_start_string)\n",
        " 的TensorFlow张量。这是因为模型通常期望接收批处理的输入，即使在生成单个序列时，\n",
        " 我们也需要提供一个批大小为 1 的输入。\n",
        "'''\n",
        "\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  # 初始化一个空列表 text_generated，用于存储模型生成的字符。\n",
        "  text_generated = []\n",
        "\n",
        "  # Low temperatures results in more predictable text.\n",
        "  # Higher temperatures results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  temperature = 1.0\n",
        "\n",
        "  # Here batch size == 1\n",
        "  #如果你的模型是一个有状态的 RNN (例如，在训练时设置了 stateful=True 的 LSTM 或 GRU)，\n",
        "  #那么这行代码会在生成文本之前重置模型的内部状态。这确保了生成过程是从一个干净的状态开始的，\n",
        "  #并且不会受到之前处理过的序列的影响。对于无状态的 RNN，这行代码没有实际作用。\n",
        "  model.reset_states()\n",
        "  for i in range(num_generate):\n",
        "      #\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "      print(f\"predictions.shape: {predictions.shape}\")  # (1, seq_length, vocab_size)\n",
        "      predictions = tf.squeeze(predictions, 0) #移除批次维度 → (seq_len, vocab_size)\n",
        "\n",
        "      # # 应用温度参数调整多样性\n",
        "      #这会调整概率分布的形状，从而影响生成文本的随机性。较高的 temperature 会使分布更平缓，增加低概率字符被选中的机会；\n",
        "      #较低的 temperature 会使分布更尖锐，模型更倾向于选择高概率字符。\n",
        "      # using a categorical distribution to predict the character returned by the model\n",
        "      predictions = predictions / temperature\n",
        "      #  tf.random.categorical(predictions, num_samples=1) ==> (seq_len, 1)\n",
        "      print(f\"categorical的形状: {tf.random.categorical(predictions, num_samples=1).shape}\")\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy() ## 从分布中采样下一个字符\n",
        "      print(f\"predicted_id: {predicted_id}\")\n",
        "      # We pass the predicted character as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      input_eval = tf.expand_dims([predicted_id], 0) # 形状: (1,1)\n",
        "      print(f\"input_eval: {input_eval}\")\n",
        "      print(f\"input_eval.shape: {input_eval.shape}\")\n",
        "      text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAJqhD9AA5mF"
      },
      "source": [
        "inp = input(\"Type a starting string: \")\n",
        "print(generate_text(model, inp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBjHrzzyOBVr"
      },
      "source": [
        "*And* that's pretty much it for this module! I highly reccomend messing with the model we just created and seeing what you can get it to do!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw-1eDE54yQo"
      },
      "source": [
        "##Sources\n",
        "\n",
        "1. Chollet François. Deep Learning with Python. Manning Publications Co., 2018.\n",
        "2. “Text Classification with an RNN &nbsp;: &nbsp; TensorFlow Core.” TensorFlow, www.tensorflow.org/tutorials/text/text_classification_rnn.\n",
        "3. “Text Generation with an RNN &nbsp;: &nbsp; TensorFlow Core.” TensorFlow, www.tensorflow.org/tutorials/text/text_generation.\n",
        "4. “Understanding LSTM Networks.” Understanding LSTM Networks -- Colah's Blog, https://colah.github.io/posts/2015-08-Understanding-LSTMs/."
      ]
    }
  ]
}